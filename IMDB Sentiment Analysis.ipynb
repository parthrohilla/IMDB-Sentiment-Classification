{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMBD Dataset and Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large movie review dataset contains a collection of 50,000 reviews from IMDB. The dataset contains an even number of positive and negative reviews. The authors considered only highly polarized reviews. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. Neutral reviews are not included in the dataset. The dataset is divided into training and test sets. The training set is the same 25,000 labeled reviews.\n",
    "\n",
    "The sentiment classification task consists of predicting the polarity (positive or negative) of a given text.\n",
    "\n",
    "To get the dataset, in your terminal run the following commands:\n",
    "\n",
    "wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "gunzip aclImdb_v1.tar.gz\n",
    "\n",
    "tar -xvf aclImdb_v1.tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from fastai.nlp import *\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path \n",
    "PATH='aclImdb/'\n",
    "names=['neg','pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\r\n",
      "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH}train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lading training and validation data \n",
    "trn,trn_y = texts_labels_from_folders(f'{PATH}train',names)\n",
    "val,val_y = texts_labels_from_folders(f'{PATH}test',names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to reviews to features by Tokenizing \n",
    "vectorizer = CountVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming reviews to features\n",
    "trn_term_doc = vectorizer.fit_transform(trn)\n",
    "val_term_doc = vectorizer.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affinity',\n",
       " 'affinité',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmations',\n",
       " 'affirmative',\n",
       " 'affirmatively',\n",
       " 'affirmed',\n",
       " 'affirming',\n",
       " 'affirms']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking vocaulary\n",
    "vocab = vectorizer.get_feature_names();vocab[2000:2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming \n",
    "x=trn_term_doc\n",
    "y=trn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88404"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using logistic regression to make predictions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=0.1,dual=True)\n",
    "lr.fit(x.sign(),y)\n",
    "preds = lr.predict(val_term_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using nGRAM Approach:-Bigram and Trigram\n",
    "I used unigrams in the previous approach,meaning each feature was a single word.\n",
    "Now using bigrams and Trigrams to predict the sentiment of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bigrams and trigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3),tokenizer=tokenize, max_features=800000)\n",
    "trn_term_doc = vectorizer.fit_transform(trn)\n",
    "val_term_doc = vectorizer.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['! the bbc',\n",
       " '! the best',\n",
       " '! the camera',\n",
       " '! the cast',\n",
       " '! the character',\n",
       " '! the characters',\n",
       " '! the cinematography',\n",
       " '! the climax',\n",
       " '! the dialog',\n",
       " '! the direction']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the vocabulary\n",
    "vocab = vectorizer.get_feature_names();\n",
    "vocab[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.sign() to binarize it number of occurences of a word aren't important\n",
    "x = trn_term_doc.sign()\n",
    "y = trn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying Logistic Regression\n",
    "lr = LogisticRegression(C=0.1,dual=True)\n",
    "lr.fit(x,y)\n",
    "preds = lr.predict(val_term_doc.sign())\n",
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
